{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGCC3iwZp3VplkchudIFwQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/billzhao1030/KIT315_Project/blob/KIT/KIT315_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Introduction***"
      ],
      "metadata": {
        "id": "ByFJlMEiswLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this KIT315 project, I developed an machine learning application to help us detecting and classifying the type of Penguin from images to help Antarctic scientific \n",
        "research. There are \n",
        "three categories I need to classify: ***Aptenodytes Forsteri (Emperor Penguin)***, ***Aptenodytes Patagonicus (King Penguin)*** and  ***Pygoscelis \n",
        "Antarciticus (Chinstrap Penguin)*** .\n",
        "<Br>\n",
        "<Br>\n",
        "In this jupyter notebook, I will describe the most important tasks I did during the ML application development, these include the data preparation, processing, and analysis, model development, evaluation and selection, and how I apply the model.\n",
        "<Br>\n",
        "<p align=\"justify\"> In this jupyter notebook, I will describe the most important tasks I did during the ML application development, these include the data preparation, processing, and analysis, model development, evaluation and selection, and how I apply the model. </p>\n",
        "<Br>\n",
        "Submission details:\n",
        "*   Student Name: Xunyi Zhao (Bill)\n",
        "*   Student ID: 560060\n",
        "*   Date: 04/10/2022\n",
        "*   Environment uses: [Google Colab](https://colab.research.google.com/)"
      ],
      "metadata": {
        "id": "P0k3y9Xf9n61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Data Preparation***\n",
        "\n"
      ],
      "metadata": {
        "id": "fwe1YeVSp20U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section I will introduce how I collect and \n",
        "annotate the data (using the [Roboflow](https://roboflow.com/) tool) which helps achieve good \n",
        "performance of the model development.\n"
      ],
      "metadata": {
        "id": "wVHWfNSRA2Qw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Data Processing***"
      ],
      "metadata": {
        "id": "vjnx7BYhqSu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, I will introduce how I identify if data processing is needed or not, and apply relevant techniques for data pre-processing using the [Roboflow](https://roboflow.com/) tool.\n"
      ],
      "metadata": {
        "id": "ow-FM2WlA29z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Data Analysis***"
      ],
      "metadata": {
        "id": "JkQGzhbjqTEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, I will perform some analysis of the data, this includes:\n",
        "\n",
        "*   Number of samples.\n",
        "*   Number of attributes/size.\n",
        "*   Is the data balance or not.\n",
        "*   Are there any missing values?\n",
        "*   The chanllenges for learning with this data.\n"
      ],
      "metadata": {
        "id": "h-CFygMLA3f3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Model Development***"
      ],
      "metadata": {
        "id": "X88eAns8p2LX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, there are **three** we need to develop:\n",
        "\n",
        "\n",
        "1.   Yolov5\n",
        "2.   Detectron2-Faster RCNN\n",
        "3.   TODO\n"
      ],
      "metadata": {
        "id": "_VYYYYburH6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to install the ***Roboflow*** to load the data (in different format)"
      ],
      "metadata": {
        "id": "hgCOgQmGpizP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "from roboflow import Roboflow"
      ],
      "metadata": {
        "id": "Fwd6O0zepfo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***YOLOv5 Model***"
      ],
      "metadata": {
        "id": "ShmDJK0srckI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRpgFV9ypIdZ",
        "outputId": "6c924b7c-e872-4adc-ab92-dd1e71bc7f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v6.2-89-g5cb9fe6 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 37.4/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone yolov5\n",
        "%cd yolov5\n",
        "%pip install -r requirements.txt  # install\n",
        "\n",
        "import utils\n",
        "display = utils.notebook_init() # check"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"pCjhgO6AaDWtsuKCrLgf\")\n",
        "project = rf.workspace(\"utas\").project(\"kit315-dequm\")\n",
        "dataset = project.version(5).download(\"yolov5\")"
      ],
      "metadata": {
        "id": "nKBAJ-S2sA9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 60 --data KIT315-5/data.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "id": "3pPx7EyGr5RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/train"
      ],
      "metadata": {
        "id": "ChN0MdRcsHq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights ./runs/train/exp/weights/best.pt  --conf 0.3 --source ./KIT315-5/test/images/"
      ],
      "metadata": {
        "id": "nwheKmpxsKlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cp ./runs/train/exp/weights/best.pt /content/gdrive/My\\ Drive/models/yolov5_tutorial_model"
      ],
      "metadata": {
        "id": "1-7J-p1DsM5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Detectron2-Faster RCNN Model***"
      ],
      "metadata": {
        "id": "soCLEPnXruFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "# !pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "# !pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "# import torch, torchvision\n",
        "# print(torch.__version__, torch.cuda.is_available())\n",
        "# !gcc --version\n",
        "\n",
        "# !pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "metadata": {
        "id": "t1uVv_ZRr2Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.data.catalog import DatasetCatalog"
      ],
      "metadata": {
        "id": "ugd-SkSVsQZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"pCjhgO6AaDWtsuKCrLgf\")\n",
        "project = rf.workspace(\"utas\").project(\"kit315-dequm\")\n",
        "dataset = project.version(5).download(\"coco\")"
      ],
      "metadata": {
        "id": "F7Ay6TFTsSYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"my_dataset_train\", {}, \"/content/KIT315-5/train/_annotations.coco.json\", \"/content/KIT315-5/train\")\n",
        "register_coco_instances(\"my_dataset_val\", {}, \"/content/KIT315-5/valid/_annotations.coco.json\", \"/content/KIT315-5/valid\")\n",
        "register_coco_instances(\"my_dataset_test\", {}, \"/content/KIT315-5/test/_annotations.coco.json\", \"/content/KIT315-5/test\")"
      ],
      "metadata": {
        "id": "QZj35AGSsV0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize training data\n",
        "my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
        "dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
        "\n",
        "import random\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "mPuG83_-sWX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "\n",
        "class CocoTrainer(DefaultTrainer):\n",
        "\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "\n",
        "    if output_folder is None:\n",
        "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
        "        output_folder = \"coco_eval\"\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ],
      "metadata": {
        "id": "VcM5N_OQsZlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from .detectron2.tools.train_net import Trainer\n",
        "#from detectron2.engine import DefaultTrainer\n",
        "# select from modelzoo here: https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md#coco-object-detection-baselines\n",
        "\n",
        "from detectron2.config import get_cfg\n",
        "#from detectron2.evaluation.coco_evaluation import COCOEvaluator\n",
        "import os\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "# faster_rcnn_R_101_FPN_3x.yaml\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 2 # Max 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4 # This is the real \"batch size\" commonly known to deep learning people\n",
        "cfg.SOLVER.BASE_LR = 0.001\n",
        "\n",
        "\n",
        "cfg.SOLVER.MAX_ITER = 1200 #adjust up if val mAP is still rising, adjust down if overfit\n",
        "# cfg.SOLVER.STEPS = (1000, 1500)\n",
        "# cfg.SOLVER.GAMMA = 0.05\n",
        "cfg.SOLVER.STEPS = [] # do not decay learning rate\n",
        "\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4 #your number of classes + 1\n",
        "\n",
        "cfg.TEST.EVAL_PERIOD = 500\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = CocoTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "HqLwkK7DscHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "LKxDLIQmscJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_test\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "metadata": {
        "id": "6zbY3iM-sgCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.DATASETS.TEST = (\"my_dataset_test\", )\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3   # set the testing threshold for this model\n",
        "predictor = DefaultPredictor(cfg)\n",
        "test_metadata = MetadataCatalog.get(\"my_dataset_test\")"
      ],
      "metadata": {
        "id": "bsjx7TGCsh_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "import glob\n",
        "\n",
        "for imageName in glob.glob('/content/KIT315-5/test/*jpg'):\n",
        "  im = cv2.imread(imageName)\n",
        "  outputs = predictor(im)\n",
        "  v = Visualizer(im[:, :, ::-1],\n",
        "                metadata=test_metadata, \n",
        "                scale=0.8\n",
        "                 )\n",
        "  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "  cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "oVOyO42NsjjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Third Model***"
      ],
      "metadata": {
        "id": "e8jMjoN4sk0i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HdHnrVKZskaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Model Evaluation and Selection***"
      ],
      "metadata": {
        "id": "ktq89ahKqTWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Train the best model***"
      ],
      "metadata": {
        "id": "sKmBHI2bB7eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the model evaluation and selection steps mentioned in previous sections, now I will train the best model - TODO, and save it for later use."
      ],
      "metadata": {
        "id": "8hyzjS59Dwyd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6z4_9msLELAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Apply Model***"
      ],
      "metadata": {
        "id": "KiBtU_lwqvVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this last section, I will apply the best model I've developed in previous steps to the new data (the samples mainly represent two different scenarios which are ***images*** and ***videos***)."
      ],
      "metadata": {
        "id": "t1B6vFgPB7Fp"
      }
    }
  ]
}